# MLOps for MLE
## Chapter 4 - Model Deployment
학습이 완료된 모델을 다른 사람들도 사용할 수 있도록 하려면 어떻게 해야할까?
기본적으로는 모델과 코드를 전달해주는 방법이 있을 수 있을 것이다. 하지만 디바이스의 환경에 따라 모델의 크기 문제, 설치되어 있는 패키지 버전 문제 등 다양한 문제에 의해 모델을 사용할 수 없는 상황이 될 수 있다. 그렇다면 그 외에도 API나 클라우드를 활용할 수 있지 않을까 하는 생각이 든다.
이번 장에서는 모델 배포에 대해 살펴보겠다. 

### Request Driven - API Serving
각자 다른 환경의 디바이스에서 모델을 사용하기에 어려움이 있다면 데이터만 주고 받는 방법은 어떨끼? 예를 들어 고양이와 개를 구분하는 모델을 만들었다면 개 또는 고양이 사진을 받아서 모델을 만든 환경에서 모델을 돌리고 그 결과를 사용자에게 전달하는 방법이 있을 수 있다. 이렇게 하면 모델을 사용하고 싶은 사람들도 모델을 직접 돌리지 않고 원하는 결과를 얻게 된다. 이와 같이 요청을 보내고 요청에 대한 응답을 받아 결과를 얻는 방식은 머신러닝 뿐만 아니라 많은 소프트웨어에서 사용하는 방식이다. 이를 **"Request-Response"** 방식이라고 부른다.   
![img](/img/4-request-api.png)

디바이스끼리 이러한 Request-Response를 하기 위해서는 요청과 응답 형식에 대한 사전의 정의하는 절차가 필요하다. 가장 대표적인 방법이 REST API이다.   

**REST API란?**
- API(Application Programming Interface): 데이터와 기능의 집합을 제공하여 컴퓨터 프로그램간 상호작용을 촉진하며, 서로 정보를 교환가능 하도록 하는 것
- REST의 정의: “Representational State Transfer”의 약자로 자원을 이름(자원의 표현)으로 구분하여 해당 자원의 상태(정보)를 주고 받는 모든 것을 의미한다.
- REST API의 정의: REST 기반으로 서비스 API를 구현한 것
- 최근 OpenAPI(누구나 사용할 수 있도록 공개된 API: 구글 맵, 공공 데이터 등), 마이크로 서비스(하나의 큰 애플리케이션을 여러 개의 작은 애플리케이션으로 쪼개어 변경과 조합이 가능하도록 만든 아키텍처) 등을 제공하는 업체 대부분은 REST API를 제공한다.


5.FastAPI 파트에서는 REST API 오픈 소스 중 가장 대중적인 FastAPI를 학습할 것이며, 6.API Serving 파트에서는 REST API를 통해 모델을 사용하고 결과를 얻는 방법에 대해 학습할 것이다.

### Event Driven - Streaming Serving
만약 데이터가 계속해서 쌓이고 있고, 실시간으로 모델을 서빙해야 한다면 어떻게 할까? 앞서 말한 방식을 채택해서 모델에 계속 요청을 보내고 결과를 반복해서 받아올 수도 있을 것이다. 하지만 이는 너무 큰 부하를 만들기도 하고, 작은 센서의 경우 요청을 보내는 기능이 없을 수 있다. 또한 결과를 받는 주체는 다른 기기인 경우도 많다. 이를 해결하기 위해서는 대신해서 요청을 보내고 결과를 수집할 수 있는 주체가 필요하다.   

위의 예시와 같이 지속적으로 데이터를 수집하고 요청을 보내 결과를 수집하는 상황을 **Stream**이라고 표현한다. 이를 위해 7.Kafka 파트에서 스트림 인프라를 주로 다루는 Kafka를 학습할 것이고, 8.Stream 파트에서는 모델에 요청을 보내서 결과를 수집하는 Stream Serving을 학습하고, 이를 Dashboard로 연결하여 시각화하는 Grafana에 대해 학습할 것이다.