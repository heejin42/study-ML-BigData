# MLOps for MLE
## Chapter 6 - API Serving

ì´ë²ˆ ì±•í„°ì—ì„œëŠ” í•™ìŠµí•œ ëª¨ë¸ì„ fastapië¥¼ ì´ìš©í•´ Request Driven ë°©ì‹ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ë°©ë²•ì„ ë°°ì›Œë³¼ ê²ƒì´ë‹¤.    
ğŸ“Œ 01. Database íŒŒíŠ¸ì˜ DB ì™€ 03. Model Registry íŒŒíŠ¸ì˜ ëª¨ë¸ì„ ì´ìš©í•˜ê¸° ë•Œë¬¸ì— 01. Database íŒŒíŠ¸ì˜ DBì™€ í•™ìŠµëœ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¬ Model Registry ë¥¼ ë„ì›Œë†“ê³  ì§„í–‰í•´ì•¼ í•œë‹¤.    

![img](./img/api-serving.png)


----------------

# ì‹¤ìŠµ - 1
## Model API
Iris ë°ì´í„°ë¥¼ ì…ë ¥ ë°›ê³  ëª¨ë¸ì„ í†µí•œ ì˜ˆì¸¡ ê°’ì„ ë°˜í™˜í•˜ëŠ” APIë¥¼ ì‘ì„±í•´ë³´ê² ë‹¤. 

### 0. í™˜ê²½ ì„¤ì •
ì´ë²ˆ íŒŒíŠ¸ì—ì„œ ì‚¬ìš©í•  íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•œë‹¤.
```
pip install boto3==1.26.8 mlflow==1.30.0 "fastapi[all]" pandas scikit-learn
```
ë˜í•œ fastapi ì„œë²„ë¥¼ ì‹¤í–‰í•  ì˜ˆì •ì´ë¯€ë¡œ í¬íŠ¸ê°€ ê²¹ì¹˜ì§€ ì•Šë„ë¡ í•˜ê¸° ìœ„í•´ ì•ì„œ ì‹¤í–‰í–ˆë˜ ì»¨í…Œì´ë„ˆë¥¼ ì¢…ë£Œì‹œí‚¤ì.
```
docker rm --force api-server
```

### 1. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ì½”ë“œ ì‘ì„±
ë¨¼ì € í•„ìš”í•œ íŒ¨í‚¤ì§€ë“¤ import í•œë‹¤.
```python
import os
from argparse import ArgumentParser
import mlflow
```

ë‹¤ìŒìœ¼ë¡œ model registryì— ì €ì¥ë˜ì–´ ìˆëŠ” ëª¨ë¸ì„ ë‹¤ìš´ë¡œë“œí•˜ê¸° ìœ„í•´ MLflow ì„œë²„ì™€ MinIO ì„œë²„ì— ì ‘ê·¼í•´ì•¼ í•œë‹¤. í•„ìš”í•œ í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì¤€ë‹¤.
```python
os.environ["MLFLOW_S3_ENDPOINT_URL"] = "http://localhost:9000"
os.environ["MLFLOW_TRACKING_URI"] = "http://localhost:5001"
os.environ["AWS_ACCESS_KEY_ID"] = "minioheejin"
os.environ["AWS_SECRET_ACCESS_KEY"] = "minio6843*"
```
ë‹¤ìŒìœ¼ë¡œ mlflow íŒ¨í‚¤ì§€ë¥¼ ì´ìš©í•´ model artifactë¥¼ ë‹¤ìš´ë¡œë“œí•œë‹¤. ì—¬ê¸°ì„œ model artifactë€ MLFlowì— ëª¨ë¸ì´ ì €ì¥ë  ë•Œ í•¨ê»˜ ì €ì¥ëœ ë©”íƒ€ ë°ì´í„°ì™€ ëª¨ë¸ ìì²´ì˜ binary íŒŒì¼ì„ ì´ì•¼ê¸°í•œë‹¤.
```python
def download_model(args):
    mlflow.artifacts.download_artifacts(artifact_uri=f"runs:/{args.run_id}/{args.model_name}", dst_path=".")
```
ì´ ì½”ë“œë¥¼ ì‹¤í–‰í•  ë•Œ ë‹¤ìš´ë¡œë“œ ì›í•˜ëŠ” ëª¨ë¸ì˜ run_idì™€ model_nameì„ ì…ë ¥í•´ì£¼ì–´ì•¼ í•˜ëŠ”ë° MLFlow ì„œë²„ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ê·¸ëŸ¼ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ í•˜ëŠ” ì½”ë“œë¥¼ ì‘ì„±í•´ë³´ê² ë‹¤. argparseë¥¼ ì´ìš©í•´ íŒŒë¼ë¯¸í„°ë¥¼ ì…ë ¥ë°›ì„ ìˆ˜ ìˆë„ë¡ í•˜ê³  download_model() í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•œë‹¤.
```python
if __name__ == "__main__":
    parser = ArgumentParser()
    parser.add_argument("--model-name", dest="model_name", type=str, default="sk_model")
    parser.add_argument("--run-id", dest="run_id", type=str)
    args = parser.parse_args()

    download_model(args)
```

ë¨¼ì € ë‹¤ìš´ë¡œë“œë°›ê³ ì í•˜ëŠ” ëª¨ë¸ì˜ MLFlow ì„œë²„ì—ì„œ ì €ì¥ëœ run_id ì™€ model_name ì„ http://localhost:5001 ì— ì ‘ì†í•˜ì—¬ í™•ì¸í•˜ì. ëª¨ë¸ì´ ì €ì¥ëœ experiments ì™€ run ì„ ì„ íƒí•˜ì—¬ í´ë¦­í•˜ê³  ì•„ë˜ ê·¸ë¦¼ì²˜ëŸ¼ ë¹¨ê°„ìƒ‰ ìƒì ë¶€ë¶„ì—ì„œ run_id ì™€ model_name ì„ ê°ê° í™•ì¸í•  ìˆ˜ ìˆë‹¤.
![img](./img/api-serving-2.png)
ê·¸ ë‹¤ìŒ ì•„ë˜ ëª…ë ¹ì–´ë¥¼ í†µí•´ download_model.pyë¥¼ ì‹¤í–‰ì‹œì¼œì„œ ëª¨ë¸ì¼ localì— ë‹¤ìš´ë¡œë“œí•˜ë©´ ëœë‹¤.
```
python3 download_model.py --model-name sk_model --run_id c175dd75b5d948e48aec04912765efe3
```

ì‹¤í–‰í•´ë³´ë©´ sk_modelì´ë¼ëŠ” í´ë”ê°€ ìƒì„±ë˜ê³  ê·¸ ì•ˆì—ëŠ” ë‹¤ìš´ë¡œë“œë°›ì€ ëª¨ë¸ê³¼ ë©”íƒ€ ë°ì´í„° ë“±ì´ ë“¤ì–´ìˆì„ ê²ƒì´ë‹¤. ê·¸ë ‡ë‹¤ë©´ ì´ì œ Model APIë¥¼ ì‘ì„±í•´ë³´ê² ë‹¤. 

sk_model
â”œâ”€â”€ MLmodel
â”œâ”€â”€ conda.yaml
â”œâ”€â”€ input_example.json
â”œâ”€â”€ model.pkl
â”œâ”€â”€ python_env.yaml
â””â”€â”€ requirements.txt


### 2. Model API ëª…ì„¸ì„œ ì‘ì„±
POST /predict ë¥¼ ìˆ˜í–‰í–ˆì„ ë•Œ í•™ìŠµí•œ ëª¨ë¸ì˜ inference ê²°ê³¼ë¥¼ ë°˜í™˜í•´ì£¼ëŠ” API ëª…ì„¸ì„œë¥¼ ì‘ì„±í•œë‹¤. Request Bodyë¡œ iris ë°ì´í„°ë¥¼ ì „ë‹¬í•´ì£¼ë©´ Response Bodyë¥¼ í†µí•´ ì˜ˆì¸¡ëœ ê°’ì„ ì „ë‹¬ë°›ê²Œ ëœë‹¤. ì´ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.   
- Request Header: POST /predict   
- Request Body: {"sepal_length": 6.7, "sepal_width": 3.3, "petal_length": 5.7, "petal_width":2.1}   
- Response Body: {"iris_class":2}

### 3. Pydantic Modelë¡œ ìŠ¤í‚¤ë§ˆ í´ë˜ìŠ¤ ì‘ì„±
schemas.py
```python
from pydantic import BaseModel

# Input Schema
class PredictIn(BaseModel):
    sepal_length: float
    sepal_width: float
    petal_length: float
    petal_width: float
# Output Schema
class PredictOut(BaseModel):
    iris_class: int
```

### 4. Predict API êµ¬í˜„
app.py
```python
import mlflow
import pandas as pd
from fastapi import FastAPI
from schemas import PredictIn, PredictOut


def get_model():
    model = mlflow.sklearn.load_model(model_uri="./sk_model")
    return model


MODEL = get_model()

# Create a FastAPI instance
app = FastAPI()


@app.post("/predict", response_model=PredictOut)
def predict(data: PredictIn) -> PredictOut:
    df = pd.DataFrame([data.dict()])
    pred = MODEL.predict(df).item()
    return PredictOut(iris_class=pred)
```

ê·¸ëŸ¼ ì‘ì„±í•œ APIë¥¼ ì‹¤í–‰í•´ë³´ê² ë‹¤.
```
uvicorn app:app --reload
```
ì´ì œ http://localhost:8000/docs (FastAPI - Swagger UI) ì— ì ‘ì†í•˜ì—¬ ì‘ë™ í…ŒìŠ¤íŠ¸ë¥¼ í•´ë³´ì. 

![img](./img/api-serving-3.png)


--------------------


# ì‹¤ìŠµ - 2
## Model API on Docker Compose
ì´ë²ˆì—ëŠ” ì•ì„œ ì‘ì„±í•œ APIë¥¼ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” Dockerfileì„ ì‘ì„±í•˜ê³  Docker Compose íŒŒì¼ì„ ì‘ì„±í•´ API ì„œë²„ë¥¼ ë„ì›Œë³´ê² ë‹¤.
![img](./img/api-serving-4.png)

### 1. Dockerfile ì‘ì„±

```
FROM amd64/python:3.9-slim

WORKDIR /usr/app

RUN pip install -U pip &&\
    pip install mlflow==1.30.0 pandas scikit-learn "fastapi[all]"

COPY schemas.py schemas.py
COPY app.py app.py
COPY sk_model/ sk_model/

CMD ["uvicorn", "app:app", "--host", "0.0.0.0", "--reload"]
```


### 2. Docker Compose ì‘ì„±
```
version: "3"

services:
  api-with-model:
    build:
      context: .
      dockerfile: Dockerfile
    container_name: api-with-model
    ports:
      - 8000:8000
    healthcheck:
      test:
        - CMD
        - curl -X POST http://localhost:8000/predict
        - -H
        - "Content-Type: application/json"
        - -d
        - '{"sepal_length": 6.7, "sepal_width": 3.3, "petal_length": 5.7, "petal_width": 2.1}'
      interval: 10s
      timeout: 5s
      retries: 5

networks:
  default:
    name: mlops-network
    external: true
```

ì´ì œ ì™„ì„±ëœ Docker Compose íŒŒì¼ì„ ë‹¤ìŒì˜ ëª…ë ¹ì–´ë¥¼ í†µí•´ ì‹¤í–‰í•˜ì—¬ Model API ì„œë¹„ìŠ¤ë¥¼ ì‘ë™ì‹œí‚¨ë‹¤.
```
docker compose up -d
```
ì»¨í…Œì´ë„ˆê°€ ì˜ ì‹¤í–‰ë˜ê³  ìˆëŠ”ì§€ í™•ì¸í•´ë³´ë©´ ë‹¤ìŒê³¼ ê°™ì´ api-with-model ì´ë¼ëŠ” ì´ë¦„ì˜ ì»¨í…Œì´ë„ˆê°€ ì‹¤í–‰ë˜ê³  ìˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
```
docker ps
CONTAINER ID   IMAGE                COMMAND                  CREATED         STATUS                 PORTS                              NAMES
a88b1a6cff44   part6-api-with-model   "uvicorn app:app --hâ€¦"   5 seconds ago   Up 4 seconds
```



### 3. API ì„œë²„ ì‘ë™ í™•ì¸

API ì„œë²„ ì»¨í…Œì´ë„ˆë¥¼ ì‹¤í–‰í•  ë•Œ í¬íŠ¸ í¬ì›Œë”©ì„ 8000:8000 ìœ¼ë¡œ í–ˆìœ¼ë¯€ë¡œ 8000ë²ˆ í¬íŠ¸ë¡œ ì ‘ì†í•˜ë©´ API ì„œë²„ë¡œ ì ‘ì†í•  ìˆ˜ ìˆë‹¤. http://localhost:8000/docs ì— ì ‘ì†í•˜ì—¬ Request Body ì˜ í˜•íƒœì— ì•Œë§ê²Œ ë°ì´í„°ë¥¼ ì „ë‹¬í•´ì£¼ë©´ Response Body ë¡œ inference ê²°ê³¼ê°€ ì˜ ë°˜í™˜ë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.    
ë˜í•œ FastAPI ì˜ Swagger UI ë¥¼ ì´ìš©í•˜ì§€ ì•Šê³  ë‹¤ìŒê³¼ ê°™ì´ curl ì„ ì´ìš©í•˜ì—¬ API ê°€ ì˜ ì‘ë™í•˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” ë°©ë²•ë„ ìˆë‹¤. 
```
curl -X POST http://localhost:8000/predict -H "Content-Type: application/json" -d '{"sepal_length": 6.7, "sepal_width": 3.3, "petal_length": 5.7, "petal_width": 2.1}'
```
ìœ„ì˜ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ ì£¼ì–´ì§„ ë°ì´í„°ì— ëŒ€í•œ ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ ({"iris_class":2}) ë¥¼ ì˜ ë°˜í™˜í•´ ì£¼ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.
```
{"iris_class":2}
```