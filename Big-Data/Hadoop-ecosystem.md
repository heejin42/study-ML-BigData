# 빅데이터 분산처리 시스템 하둡(Hadoop)
하둡이란 간단한 프로그래밍 인터페이스를 활용해 대용량 데이터를 빠르게 유연하게 분산처리할 수 있는 소프트웨어 라이브러리다. 과거, 데이터를 읽고 처리하는 속도가 데이터의 양을 따라잡지 못하는 문제를 해결하기 위해 분산처리 개념이 출발하게 되었다.

### 키워드 1. scalable
하둡의 스케일은 확장 가능하다는 특징이 있다. 그래서 자원을 추가하더라도 코드의 수정 등을 할 필요 없이 동일한 방법으로 프로세싱이 가능하다.

### 키워드 2. distributed computing
분산 컴퓨팅을 특징으로 한다. 이는 하나의 Job을 적절한 크기로 쪼갠 후, 분산된 자원을 통해 계산하고 결과를 합치는 작업을 수행한다.

## Hadoop 구조
![img](./img/hadoop-structure.png)

하둡을 이해하기 위해서는 여러 대의 컴퓨터를 통해 손쉽게 대규모 데이터를 처리하는 Map-Reduce라는 데이터 처리 모델을 알아야 하며, 분산 파일 시스템 HDFS의 작동 원리를 이해해야 한다.

## 맵리듀스(MapReduce)
맵리듀스란 분산 컴퓨팅을 위한 프레임워크로, 하둡의 서브 프로젝트에 속한다. 주요 역할로는 job의 스케줄링, 모니터링, 에러 핸들링 등이 있다. 또한 입력 데이터를 독립적인 청크로 나누고 이를 병렬적으로 처리한다. 이 과정에서 하둡 분산 파일 시스템(Hadoop Distributed File System)으로부터 데이터를 불러오고 저장할 수 있다.
예를 들어보자. 100개의 문서가 입력으로 들어오고 모든 문서의 특정 단어 빈도수를 세어야 하는 작업이 요청될 때, 1개의 컴퓨터가 차례로 작업할 수도 있겠지만 100개의 컴퓨터에 하나씩 나눠서 처리하는 것이 더 빠를 것이다. 간단해 보이지만 이렇게 데이터를 나누는 것도, 각각의 컴퓨터에서 계산한 빈도수를 합쳐서 보여주는 것도 특정 컴퓨터나 단계의 에러가 발생하거나 자원의 부족으로 어려울 수 있다. 그래서 이러한 모든 상황을 고려해서 작동하는 하나의 분산 컴퓨팅 프레임워크가 필요한 것이다.

- Map: 빅데이터에서 쪼개진 데이터를 어떻게 처리할 것인지 작성하는 함수
- Shuffle and Sort: map에서 처리한 결과물을 나눠주는 것 -> 하둡 엔진이 한다.
- Reduce: 최종 집계해서 결과를 내는 함수
즉 개발자는 결국 Map 함수와 Reduce 함수를 정의하면 된다. 참고로 맵에서는 리듀스를 위한 키-값 쌍을 만들어내고, 이 키-값 쌍은 사용자에 의해 정의될 수 있다. 리듀스는 맵의 아웃풋 키-값 쌍을 인풋으로 받아서 최종 결과를 출력한다.

### 맵 리듀스 분산 병렬 처리 방식
1. 시스템(하둡)이 map() 함수들을 데이터에 배포
2. map() 함수는 데이터를 읽고 <key, value>를 출력
3. 시스템(하둡)이 <key, value> 데이터를 그룹핑(shuffle and sort)
4. 시스템(하둡)이 그룹핑된 데이터를 reduce() 함수들에 배포
5. reduce() 함수는 <key, value>를 읽고 결과를 출력

## HDFS


# Hadoop ecosystem
![img](./img/hadoop-ecosystem.png)
hadoop ecosystem은 hadoop framework를 이루고 있는 다양한 소프트웨어 및 project들의 모임이다. 
그 구성요소들을 하나씩 살펴보자
## Spark
