# 빅데이터 분산처리 시스템 하둡(Hadoop)
하둡이란 간단한 프로그래밍 인터페이스를 활용해 대용량 데이터를 빠르게 유연하게 분산처리할 수 있는 소프트웨어 라이브러리다. 과거, 데이터를 읽고 처리하는 속도가 데이터의 양을 따라잡지 못하는 문제를 해결하기 위해 분산처리 개념이 출발하게 되었다.

### 키워드 1. scalable
하둡의 스케일은 확장 가능하다는 특징이 있다. 그래서 자원을 추가하더라도 코드의 수정 등을 할 필요 없이 동일한 방법으로 프로세싱이 가능하다.

### 키워드 2. distributed computing
분산 컴퓨팅을 특징으로 한다. 이는 하나의 Job을 적절한 크기로 쪼갠 후, 분산된 자원을 통해 계산하고 결과를 합치는 작업을 수행한다.

## Hadoop 구조
![img](./img/hadoop-structure.png)

하둡을 이해하기 위해서는 여러 대의 컴퓨터를 통해 손쉽게 대규모 데이터를 처리하는 Map-Reduce라는 데이터 처리 모델을 알아야 하며, 분산 파일 시스템 HDFS의 작동 원리를 이해해야 한다.

## 맵리듀스(MapReduce)
맵리듀스란 분산 컴퓨팅을 위한 프레임워크로, 하둡의 서브 프로젝트에 속한다. 주요 역할로는 job의 스케줄링, 모니터링, 에러 핸들링 등이 있다. 또한 입력 데이터를 독립적인 청크로 나누고 이를 병렬적으로 처리한다. 이 과정에서 하둡 분산 파일 시스템(Hadoop Distributed File System)으로부터 데이터를 불러오고 저장할 수 있다.
예를 들어보자. 100개의 문서가 입력으로 들어오고 모든 문서의 특정 단어 빈도수를 세어야 하는 작업이 요청될 때, 1개의 컴퓨터가 차례로 작업할 수도 있겠지만 100개의 컴퓨터에 하나씩 나눠서 처리하는 것이 더 빠를 것이다. 간단해 보이지만 이렇게 데이터를 나누는 것도, 각각의 컴퓨터에서 계산한 빈도수를 합쳐서 보여주는 것도 특정 컴퓨터나 단계의 에러가 발생하거나 자원의 부족으로 어려울 수 있다. 그래서 이러한 모든 상황을 고려해서 작동하는 하나의 분산 컴퓨팅 프레임워크가 필요한 것이다.

- Map: 빅데이터에서 쪼개진 데이터를 어떻게 처리할 것인지 작성하는 함수
- Shuffle and Sort: map에서 처리한 결과물을 나눠주는 것 -> 하둡 엔진이 한다.
- Reduce: 최종 집계해서 결과를 내는 함수
즉 개발자는 결국 Map 함수와 Reduce 함수를 정의하면 된다. 참고로 맵에서는 리듀스를 위한 키-값 쌍을 만들어내고, 이 키-값 쌍은 사용자에 의해 정의될 수 있다. 리듀스는 맵의 아웃풋 키-값 쌍을 인풋으로 받아서 최종 결과를 출력한다.

### 맵 리듀스 분산 병렬 처리 방식
1. 시스템(하둡)이 map() 함수들을 데이터에 배포
2. map() 함수는 데이터를 읽고 <key, value>를 출력
3. 시스템(하둡)이 <key, value> 데이터를 그룹핑(shuffle and sort)
4. 시스템(하둡)이 그룹핑된 데이터를 reduce() 함수들에 배포
5. reduce() 함수는 <key, value>를 읽고 결과를 출력

## HDFS(Hadoop Distributed File System)
하둡은 HDFS라는 분산 파일시스템을 제공한다. 데이터가 단일 물리 머신의 저장 용량을 초과하게 되면 전체 데이터 셋을 분리해서 여러 머신에 나눠 저장할 수 있다. 네트워크로 연결된 여러 머신의 스토리지를 관리하는 파일 시스템이 바로 HDFS다. 분산 파일 시스템은 네트워크 기반이므로 일반적인 디스크 파일 시스템보다 훨씬 복잡하다. 하지만 기존에는 대용량 파일 시스템을 구축하려면 고성능의 서버나 대용량 스토리지가 필요했지만 HDFS의 등장으로 수십~수백대의 웹서버 수준의 서버나 저사양 서버를 이용헤 스토리지를 구성할 수 있게 된다.   
이때 HDFS에 저장되는 데이터는 물리적으로 분산된 서버의 로컬 디스크에 저장되고, 파일의 읽기와 쓰기 등의 제어는 HDFS의 API를 통해 처리된다. 

### HDFS의 구조
![img](./img/HDFS.png)
![img](./img/HDFS-block.png)
HDFS는 블록 구조의 파일 시스템이다. 

### HDFS 설계 목표
1. 장애 복구
HDFS를 구성하는 분산 서버들에는 여러가지 다양한 장애가 발생될 수 있다. 대표적으로는 사용 중인 하드디스크에 문제가 있어 데이터 저장을 실패할 수도 있고 디스크 복구가 불가능해 데이터가 유실되는 심각한 문제도 발생할 수 있다. HDFS는 이러한 장애들을 빠른 시간에 감지하고 대처할 수 있도록 설계되어 있다. 예를 들어 HDFS에 데이터를 저장하게 되면 복제 데이터가 생상되어 다른 곳에 저장되는 방식으로 데이터 유실을 방지한다.

2. 스트리밍 방식의 데이터 접근
HDFS는 클라이언트의 요청을 빠른 시간에 처리하는 것보다 동일 시간 내 많은 데이터를 처리하는 것을 목표로 하고 있다. 그러므로 인터넷 뱅킹이나 쇼핑몰 등 특정 데이터 일부를 접근하는 작업이 잦는 경우는 기존 파일 시스템을 사용하는 것이 적합하며 전체적인 데이터를 보고 분석하고 처리하는 그러한 경우에 스트리밍 방식으로 데이터에 접근할 수 있도록 설계해서 끊김없이 연속된 데이터 흐름을 얻을 수 있다.

3. 대용량 데이터 저장
HDFS는 하나의 파일이 기가 바이트에서 테라 바이트, 그 이상의 크기도 저장할 수 있도록 설계되어 있다. 하나의 클러스터에서 수백 대의 노드를 지원할 수 있고 하나의 인스턴스에서 수백만개 이상의 파일 처리를 지원한다.

4. 데이터 무결성
데이터무결성이란 저장되는 데이터의 일관성을 의미한다. 한번 저장한 데이터는 수정할 수 없고 읽기만 가능하게 하여 데이터 무결성을 유지하게 된다. 데이터 수정은 불가능하지만 파일 이동, 삭제, 복사할 수 있는 인터페이스는 제공한다.

# Hadoop ecosystem
![img](./img/hadoop-ecosystem.png)
hadoop ecosystem은 hadoop framework를 이루고 있는 다양한 소프트웨어 및 project들의 모임이다. 그 구성요소들을 하나씩 살펴보자.

### 분산환경 관리자 ZooKeeper
하둡의 이름이 코끼리에서 시작해서 그런가 하둡 서브 프로젝트들이 대부분 동물과 관련된 이름을 가지고 있다. 그래서 이러한 요소들을 관리하는 역할로 분산환경 관리자 ZooKeeper가 등장했다. 역할은 다음과 같다.
- 여러 서버에 서비스를 알맞게 분산하여 동시에 처리한다.
- 각 서버에서 처리한 결과를 다른 서버에도 동기화해서 데이터 안정성을 보장한다.
- 운영(active) 서버에서 문제가 발생해서 서비스를 제공할 수 없는 경우, 다른 대기 중인 서버를 운영 서버로 바꿔서 서비스가 중지없이 제공되도록 한다.
- 분산 환경을 구성하는 서버들의 환경설정을 통합적으로 관리한다.

https://dodonam.tistory.com/390#google_vignette
https://velog.io/@holicme7/Apache-Kafka-%EC%B9%B4%ED%94%84%EC%B9%B4%EB%9E%80-%EB%AC%B4%EC%97%87%EC%9D%B8%EA%B0%80

## 데이터 수집과 저장 요소
### Flume
분산된 서버에 에이전트가 설치되고 각 에이전트가 데이터를 전달받는 방식으로 작동된다. 전체 데이터의 흐름을 마스터 서버가 관리하는데, 마스터 서버는 데이터의 수집 위치와 전송 방식을 결정하고 동적으로 변경할 수 있다.

### Kafka
실시간 스트림 데이터를 관리하기 위한 분산 메시징 시스템이다. 링크드인에서 ㄱ.

## Spark

